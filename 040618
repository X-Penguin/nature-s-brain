Spontaneous solutions
Working with Günter Wagner from Yale University and others, Watson built a model network in which genes can either increase or reduce each other’s activity, as they do in nature. Each network configuration controls how the genes within it interact to give rise to a different phenotype, presented in the form of a pixelated image on a screen. The modellers evolved the network by randomly changing the gene connections, one mutation at a time, and selecting those networks that produced an image with a closer resemblance to one deemed to be the optimal phenotype – a picture of Darwin’s face. Thus guided, the evolving system eventually reproduced this image, at which point the team used the same process to teach it to reproduce Hebb’s face.

与耶鲁大学的金特·瓦格纳（Günter Wagner）一起， 沃森制作了一个基因网络模型，基因可以在其中增强或削弱自身和其他基因的活跃度，就像自然过程中的那样。每个网络的结构控制基因如何相互作用，并由此产生一种不同的表现型。不同的表现型会在屏幕上以马赛克图像的方式表现出来。研究人员通过随机改变基因网络的连接，一次一个突变来让基因网络得到进化。和目标——一张达尔文人像——更接近的基因网络在每一代被作为优胜者挑选出来。如此下去，这个网络模型能够重现达尔文的脸。然后用同样的步骤继续训练这个模型，海布（上文中的Donald Hebb，提出了Hebbian learning）的脸也能够被重现。

But here came the surprise. The modellers then removed the selection pressure guiding the system towards mugshots of Darwin or Hebb. Any old mutation that arose was allowed to survive. But the system did not produce a random image, or a Darwin-Hebb mash-up. Instead, it produced one or the other face – and as little as a single gene mutation was enough to trigger a flip between the two. In other words, a model that simply took account of genes’ networked nature showed that when the genotype had learned solutions, it could remember them and reproduce them in different environments – as indeed our brains can.

接下来到了见证奇迹的时刻。研究人员取消了每一步的选择压力，所有的突变都能存活（译者注：即便产生的图像不像达尔文或者海布也不会被淘汰）。但这个模型系统并没有产生随机的杂乱无章的图片，也没有产生混合达尔文和海布特征的图片。与之相反的，这个模型只会产生达尔文或海布的脸。仅仅一个连接突变就能够让模型从产生达尔文的脸转变成产生海布的脸。换句话说，这个只基于网络结构的模型能够记住“习得”的解决方案，并能够在不同的环境下进行重现。（译者：就是说这个模型在不改变基因的情况下，仅仅通过改变基因之间是如何连接的，就能够产生不同的表现型。）

Evidence for learning in this sense is often seen in the natural world, for instance in the way a crocodile genome can produce a male or female crocodile depending on the temperature at which the egg is incubated. But learning the way our brains do it is not just about remembering and reproducing past solutions. “A real learning system also has to be able to generalise – to produce good solutions even in new situations it hasn’t encountered before,” says Watson. Think crossing a road you’ve never crossed before versus crossing a familiar one.

这种网络学习的证据在自然界中也广泛存在。比如鳄鱼的基因可以根据孵化温度决定出生的小鳄鱼的性别。但我们大脑的学习方式并不仅仅是记住并重复以往的解决问题的方法。“一个真正的学习系统要能够进行举一反三，即遇到过去从未出现的问题也能有好的办法解决，”沃森说。就像穿过一条熟悉的马路和穿过一条以前没有走过的马路。

This generalisation ability rests in recognising similarities between new and old problems, so as to combine the building blocks of past solutions to tackle the problem at hand. And as another model created by Watson and his colleagues showed last year, this kind of learning is also what a gene network does under the pressure of natural selection. The cost associated with making gene connections – proteins must be produced and energy expended – favours networks with fewer connections. Subsets of connections that work well together become bound tightly in blocks that themselves are only loosely associated. Just as our brains do, natural selection memorises partial solutions – and these building blocks are embedded in the structure of the gene network (arxiv.org/abs/1508.06854).

这种举一反三的能力取决于认识到旧的问题和新的问题之间的相似之处，并且能够把以往问题的解决方案中的模块重新组合以解决新的问题。沃森和他的同事去年创建了一个新的模型表明，这也正是基因网络在自然选择压力下的学习方式。因为让不同的基因之间能够产生联系需要生成蛋白质并消耗能量，所以连线比较稀疏的网络更有优势。能够产生协同作用的基因之间会形成一个连接紧密的子网络，这些子网络模块之间形成稀疏相连，形成一个大的基因网络。和我们大脑一样，自然选择会记住这些部分解决方案（子网络模块），并把它们嵌入到基因网络中。（译者：可以把有待解决的大的问题拆分成一个个更小的问题去解决。一个连接紧密的子网络（模块）可以看作是某一个小问题的解决方案。把所有的小的解决方案组合起来，就是大问题的解决方案。在进化中，有些用来解决以往问题的子网络模块可以被重新组合，去解决新的问题。）

This way of working allows genotypes to generate phenotypes that are both complex and flexible. “If past selection has shaped the building blocks well, it can make solving new problems look easy,” says Watson. Instead of merely making limbs longer or shorter, for example, evolution can change whether forelimbs and hindlimbs evolve independently or together. A single mutation that changes connections in the network can lengthen all four legs of a giraffe, or allow a bat to increase its wingspan without getting too leggy. And a feather or an eye needn’t be generated from scratch, but can evolve by mixing and matching building blocks that have served well in the past (see diagram).

这种办法使得基因能够生成复杂而又灵活的性状（表现型）。沃森说：“如果过去的自然选择把子模块打磨的很好，那么用它们来解决新的问题会变得很容易。”进化不仅能让肢体变长或变短，它还能决定前肢和后腿是否同时进化或独立进化。一个（基因网络）连接的突变能让长颈鹿的四条腿一起变长，也能让蝙蝠的翼展变宽的同时不改变其双腿的长度。类似的，羽毛或眼睛并不是从零开始打造的，而是进化过程中把一堆过去形成的好用的子模块进行混合匹配的结果。

This ability to learn needs no supernatural intervention – it is an inevitable product of random variation and selection acting on gene networks. “Far from being blind or dumb, evolution is very smart,” says Watson.

这种学习能力并不需要超自然的干预，这只是作用在基因网络上的随机突变和自然选择的必然结果。沃森说：“（进化）一不瞎，二不傻，它是非常聪明的。”（理查德·道金斯（Richard Dawkins，牛津大学教授，《自私的基因》作者）有一本书叫《盲人钟表匠》，形容进化选择像一个盲人但塑造出了很精密的生物。沃森这里的瞎和傻应该是指此前进化生物学的一些观点对进化的描述。译者注。）

Watson’s idea has caught the attention of respected evolutionary theorists, among them Eörs Szathmáry of the Parmenides Foundation in Munich, Germany. “It is absolutely new,” he says. “I thought that the idea was so fascinating and so interesting that I should put some support behind it.” Earlier this year, he and Watson collaborated on a paper called “How Can Evolution Learn?” to discuss some of its implications (Trends in Ecology and Evolution, vol 31, p 146).

For a start, if evolution learns, by definition it must get better at what it does. It will not only evolve new adaptations, but improve its ability to do so. This notion, known as the evolution of evolvability, has been around for some time, but is contentious because it seems to require forethought. No longer. “If you can do learning, then you are able to generalise from past experience and generate potentially useful and novel combinations,” says Szathmáry. “Then you can get evolvability.”

Applying similar ideas might also begin to explain how ecosystems evolve (see “Eco-learning“). More speculatively, Watson and Szathmáry suggest that the marriage between learning theory and evolutionary theory could throw light on the giant leaps made by evolution in the past 3.8 billion years. These “major transitions”, an idea first formulated by Szathmáry and John Maynard Smith in the 1990s, include the jumps from replicating molecules to cellular organisms, from single-celled to multicellular organisms and from asexual to sexual reproduction. Szathmáry and Watson think the key might lie in a model known as deep learning.

This was how Google DeepMind beat the world’s top player at the ancient and fiendish game of Go earlier this month. It is based on Hebbian learning, with the difference that it “freezes” successive levels of a network once it has learned as much as it can, using the information acquired as the starting point for the next level. “It’s intriguing that evolutionary algorithms exploiting deep learning can solve problems that single-level evolution cannot,” says Watson – although he admits the details of the parallel are still to be worked out. If we could tease out the circumstances required to produce a major transition, that might suggest where evolution is heading next – or even how to engineer a transition. For example, says Watson, it might show us how to transform a community of microbes into a true multicellular organism.

Other evolution researchers are also intrigued. “Watson and Szathmáry are right in recognising that a species’ evolutionary history structures its genes in much the same way that an individual’s learning history structures its mind,” says Mark Pagel of the University of Reading, UK. David Sloan Wilson at Binghamton University, New York, thinks it could be an important step forward too. “In the past, it has been heretical to think about evolution as a forward-looking process, but the analogy with learning – itself a product of evolution – is quite plausible,” he says.

Szathmáry thinks we can fruitfully see that analogy from both ends. If evolution and cognitive learning are based on the same principles, we can use our understanding of either to throw new light on the other. With that in mind, he is now co-opting evolutionary theory to investigate the long-standing puzzle of how infants learn language so easily with no formal teaching and little other input.

Those infants may now grow up with a better grasp on the processes underlying that greatest of theories, evolution by natural selection. If evolution looks smart, that’s because it is, says Watson. “The observation that evolutionary adaptations look like the product of intelligence isn’t evidence against Darwinian evolution – it’s exactly what you should expect.”

Eco-learning
How does a forest develop the ability to share limited resources such as light and water? It’s a puzzle how such seemingly harmonious environments develop from a collection of individuals of different species. “There’s currently no general theory of how ecosystems evolve,” says Richard Watson at the University of Southampton, UK.

By thinking about the genes within organisms as networks, Watson has shown that evolution can learn from the past to solve new problems of survival (see main story). But the same might apply to ecological networks, he thinks.

There is a big difference: ecosystems must “learn” unaided by natural selection because it only favours fit individuals, not fit communities. Computer scientists have a way to model such “unsupervised” learning. Instead of guiding an evolving network towards a solution to a given problem, they use a rule that reinforces already common correlations. Such algorithms are known to efficiently discover categories, clusters and regularities in data sets. Working with his Southampton colleague Daniel Power and others, Watson has used them to model learning in the evolution of an ecological network (Biology Direct, vol 10, p 69).

Remarkably, ecosystem networks allowed to evolve in this way retain collective memories – information about ecological interactions that have produced successful structures and behaviours in the past. This could explain why a damaged coral reef can revert to its former composition if left to recover, or why a rainforest can recover from fragmentation.

It also suggests that if an ecosystem faces a challenge it has encountered in the past, it may be more able to recover than in the face of a new challenge. In theory, an ecosystem’s collective memory could be extremely long, because of being etched into the genomes of the organisms that comprise it. An ecosystem that has experienced warming in the past, for example, might be better equipped to cope with global warming now.
